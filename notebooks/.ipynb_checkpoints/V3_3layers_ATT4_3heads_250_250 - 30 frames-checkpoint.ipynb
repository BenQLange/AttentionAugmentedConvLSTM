{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Helpers import MSE, SSIM, MapSimilarityMetric\n",
    "import math\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "import hickle as hkl\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "from AttentionPredNetOriginalV3 import AttentionPredNetOriginalV3\n",
    "from six.moves import cPickle\n",
    "from time import time\n",
    "#from kitti_settings import *\n",
    "from kitti_data import KITTI\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mod1:\\n -Using ConvLSTMCellPredNet\\n -AttCovnLSTM with peephole\\n -No fusing output\\n -No bias in SpatioTemporalAttConv2d\\n -Each head has a full dim\\n '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Mod1:\n",
    " -Using ConvLSTMCellPredNet\n",
    " -AttCovnLSTM with peephole\n",
    " -No fusing output\n",
    " -No bias in SpatioTemporalAttConv2d\n",
    " -Each head has a full dim\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 128, 128, 2)\n",
      "SpatialAttention check: True\n",
      "SpatialAttention check: True\n",
      "SpatialAttention check: True\n",
      "SpatialAttention check: True\n",
      "Using GPU.\n",
      "1918094\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = \"\"\n",
    "\n",
    "def load_config(config_name):\n",
    "    with open(os.path.join(CONFIG_PATH, config_name)) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "config = load_config(\"../configs/V3_3layers_ATT4_3heads_250_250.yaml\")\n",
    "\n",
    "#Setting up the model\n",
    "nt = config[\"model\"][\"nt\"] # number of timesteps used for sequences in training\n",
    "nb_layers = config[\"model\"][\"nb_of_layers\"]\n",
    "(n_channels, im_height, im_width) = tuple(config[\"model\"][\"input_shape\"])\n",
    "input_shape = (im_height, im_width, n_channels)\n",
    "stack_sizes = (n_channels, *tuple(config[\"model\"][\"stack_sizes\"]))\n",
    "R_stack_sizes = stack_sizes\n",
    "A_filt_sizes = tuple(config[\"model\"][\"A_filt_sizes\"])\n",
    "Ahat_filt_sizes = tuple(config[\"model\"][\"Ahat_filt_sizes\"])\n",
    "R_filt_sizes = tuple(config[\"model\"][\"R_filt_sizes\"])\n",
    "layers_type = config[\"model\"][\"type_of_all_layers\"]\n",
    "attention_horizon = config[\"model\"][\"attention_horizon\"]\n",
    "Nh = config[\"model\"][\"Nh\"]\n",
    "dk = config[\"model\"][\"key_query_dimension\"]\n",
    "dv = config[\"model\"][\"value_dimension\"]\n",
    "\n",
    "#Setting up training\n",
    "model_name = config[\"training\"][\"model_name\"]\n",
    "data_directory = config[\"training\"][\"dataset_path\"]\n",
    "nb_epoch = config[\"training\"][\"nb_epochs\"]\n",
    "batch_size = config[\"training\"][\"batch_size\"]\n",
    "samples_per_epoch =  config[\"training\"][\"samples_per_epoch\"]\n",
    "N_seq_val = config[\"training\"][\"N_seq_val\"]\n",
    "save_model = config[\"training\"][\"save_model\"]\n",
    "\n",
    "\n",
    "val_file = os.path.join(\"../\"+data_directory, 'X_val.hkl')\n",
    "val_sources = os.path.join(\"../\"+data_directory, 'sources_val.hkl')\n",
    "kitti_val = KITTI(val_file, val_sources, nt)\n",
    "val_loader = DataLoader(kitti_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = AttentionPredNetOriginalV3(layers_type, stack_sizes, R_stack_sizes,\n",
    "                  A_filt_sizes, Ahat_filt_sizes, R_filt_sizes, attention_horizon,\n",
    "                  dk, dv, Nh, im_width, im_height, output_mode ='prediction',\n",
    "                  extrap_start_time = 5, positional_encoding= True)\n",
    "\n",
    "checkpoint = torch.load(\"../models/{}/{}_t+5.pt\".format(model_name, model_name))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using GPU.')\n",
    "    model = model.cuda()\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((496,20,128,128,1))\n",
    "X_test_seperated = np.zeros((496,20,128,128,2))\n",
    "X_hat = np.zeros((496,20,128,128,1))\n",
    "X_hat_seperated = np.zeros((496,20,128,128,2))\n",
    "mse_model = 0\n",
    "ssim_model = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, inputs in enumerate(val_loader):\n",
    "\n",
    "        inputs = inputs.permute(0, 1, 4, 2, 3)# batch x time_steps x channel x width x height\n",
    "        inputs = inputs.cuda()\n",
    "        prediction = model(inputs) # batch x n_layers x nt\n",
    "\n",
    "        output_tensor_prednet = prediction.permute(0,1,3,4,2).cpu().data.numpy()\n",
    "        input_tensor = inputs.permute(0, 1, 3, 4, 2).cpu().data.numpy()\n",
    "\n",
    "        input_test = np.expand_dims(0.5*(input_tensor[:,:,:,:,0])+ 0.5*(1.-input_tensor[:,:,:,:,1]), axis=-1)\n",
    "        output = np.expand_dims(0.5*(output_tensor_prednet[:,:,:,:,0])+ 0.5*(1.-output_tensor_prednet[:,:,:,:,1]), axis=-1)\n",
    "\n",
    "        X_test[i,:] = input_test\n",
    "        X_hat[i,:] = output\n",
    "        X_test_seperated[i,:,:,:,0] = input_tensor[0,:,:,:,0]\n",
    "        X_test_seperated[i,:,:,:,1] = input_tensor[0,:,:,:,1]\n",
    "        X_hat_seperated[i,:,:,:,0] = output_tensor_prednet[0,:,:,:,0]\n",
    "        X_hat_seperated[i,:,:,:,1] = output_tensor_prednet[0,:,:,:,1]\n",
    "\n",
    "mse_model,_ = MSE(X_test,X_hat, start_time=1) \n",
    "mse_prev = np.mean( (X_test[:, :-1] - X_test[:, 1:])**2)\n",
    "\n",
    "num_images, num_timesteps, _, _, _ = X_test.shape\n",
    "\n",
    "# ssim_values = []\n",
    "\n",
    "\n",
    "print(\"Model: {} MSE Score: {}\".format(model_name, mse_model))\n",
    "#print(\"Model: {} SSIM Score: {}\".format(model_name,ssim_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_pred,_ = MSE(X_test,X_hat, start_time=5) \n",
    "print(\"MSE Score of prediction: {}\".format(mse_pred))\n",
    "mse_seq,_ = MSE(X_test,X_hat, start_time=1) \n",
    "print(\"MSE Score of entire sequence: {}\".format(mse_seq))\n",
    "# ssim_pred,_ = SSIM(X_test,X_hat, start_time=5) \n",
    "# print(\"MSE Score of prediction: {}\".format(ssim_pred))\n",
    "# ssim_seq,_ = SSIM(X_test,X_hat, start_time=1) \n",
    "# print(\"MSE Score of entire sequence: {}\".format(ssim_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data_label = []\n",
    "data.append(X_hat)\n",
    "data_label.append(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scenario_list = [323, 324, 88, 319, 141, 323, 8, 77]\n",
    "models_considered = [0,1]\n",
    "print(X_hat[scenario_list,:,:,:,0].shape)\n",
    "print(X_test[scenario_list,:,:,:,0].shape)\n",
    "np.save(\"../export/\"+model_name+\"_prediction_scenario_20\", X_hat[scenario_list,:,:,:,0])\n",
    "#np.save(\"../export/\"+model_name+\"_prediction_full_20\", X_hat[:,:,:,:,0])\n",
    "np.save(\"../export/X_test_scenario_20\", X_test[scenario_list,:,:,:,0])\n",
    "#np.save(\"../export/X_test_full_20\", X_test[:,:,:,:,0])\n",
    "img = 0\n",
    "\n",
    "for i in scenario_list:\n",
    "    num_models = len(data_label)\n",
    "    aspect_ratio = float(X_test.shape[2]) / X_test.shape[3]\n",
    "    plt.figure()\n",
    "    fig = plt.figure(figsize = (2*(nt-5), 5.*aspect_ratio))\n",
    "    gs = gridspec.GridSpec(num_models+1, nt) #All models and a ground truth.\n",
    "    gs.update(wspace=0.0, hspace=0.0)\n",
    "    fig.suptitle('Scenario: {}'.format(i))  \n",
    "    for t in range(6,nt):\n",
    "\n",
    "        plt.subplot(gs[t])\n",
    "        plt.tick_params(bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_test[i,t,:,:,0], interpolation='nearest')\n",
    "\n",
    "        if t==6: plt.ylabel(\"Ground Truth\", fontsize=10)\n",
    "        idx = 0\n",
    "        for model in range(num_models):\n",
    "            plt.subplot(gs[t + (idx+1)*nt])\n",
    "            X_hat = data[model]\n",
    "            label = data_label[model]\n",
    "            plt.tick_params(bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "            plt.axis('off')\n",
    "            plt.imshow(X_hat[i,t,:,:,0], interpolation='nearest')\n",
    "\n",
    "            plt.tick_params(bottom='off', top='off', left='off', right='off', labelbottom='off', labelleft='off')\n",
    "            if t==6: plt.ylabel(\"Model:\" + str(model), fontsize=10)\n",
    "            idx += 1\n",
    "    num_images, num_timesteps, _, _, _ = X_test.shape\n",
    "\n",
    "\n",
    "\n",
    "   # plt.savefig(\"final_output_\" + str(img))\n",
    "    img += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
